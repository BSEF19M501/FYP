{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Optimal Selection of Features for Gait Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "from scipy.io import mmread\n",
    "import scipy.io\n",
    "# import fishervectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subject Folder: fyc\n",
      "\n",
      "Sequence Folder: fyc/00_1\n",
      "\n",
      "Video Path: fyc00_1.avi\n",
      "\n",
      "Videos\\fyc\\00_1\\fyc00_1.avi\n",
      "Video Path: C:\\Users\\LENOVO\\Desktop\\AIM\\Videos\\fyc\\00_1\\fyc00_1.avi\n",
      "\n",
      "Using cv2 to load video\n",
      "Loaded video in 0.12 seconds\n",
      "\n",
      "Now extracting HOG features. Timings below include loading the video (as in our paper):\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'compute'\n> Overload resolution failed:\n>  - HOGDescriptor.compute() takes at most 4 arguments (5 given)\n>  - HOGDescriptor.compute() takes at most 4 arguments (5 given)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-4e7dd8727ecf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrunCode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-c9f2931b2f57>\u001b[0m in \u001b[0;36mrunCode\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;31m# runCompleteCode(videoPath)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mrunFisherConcatPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideoPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubjectName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequenceName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;31m# runNewCode(videoPath, subjectName, sequenceName)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-a051c739f425>\u001b[0m in \u001b[0;36mrunFisherConcatPCA\u001b[1;34m(videoPath, subjectName, sequenceName)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Extract features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mhogDesc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhogInfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhofDesc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhofInfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMBHRowDesc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMBHColDesc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmbhInfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhmgDesc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhmgInfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextractFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvideoReadTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Performing binning & normalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-5790ca386164>\u001b[0m in \u001b[0;36mextractFeatures\u001b[1;34m(vid, videoReadTime)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# Get HOG descriptors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mhogDesc_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhogInfo_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideo2DenseHOGVolumes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampledVid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblockSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumBlocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumOr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mhogDesc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhogDesc_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mhogInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhogInfo_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-20b1852fd6ad>\u001b[0m in \u001b[0;36mVideo2DenseHOGVolumes\u001b[1;34m(video, blockSize, numBlocks, numOr)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Compute HOG descriptors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mhog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHOGDescriptor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mhogDesc_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhogInfo_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwinStride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblockSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblockSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblockSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblockSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblockSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcellSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblockSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblockSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumOr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# Reshape the HOG descriptors into a volume\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'compute'\n> Overload resolution failed:\n>  - HOGDescriptor.compute() takes at most 4 arguments (5 given)\n>  - HOGDescriptor.compute() takes at most 4 arguments (5 given)\n"
     ]
    }
   ],
   "source": [
    "runCode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def loadVideo(videoPath):\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    if not os.path.exists(videoPath):\n",
    "        raise ValueError(f'Video file \"{videoPath}\" does not exist')\n",
    "\n",
    "    print('Using cv2 to load video')\n",
    "    start_time = time.time()\n",
    "    cap = cv2.VideoCapture(videoPath)\n",
    "    \n",
    "    # Read the frames of the video\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    \n",
    "    vid = frames\n",
    "    videoReadTime = time.time() - start_time\n",
    "    print(f'Loaded video in {videoReadTime:.2f} seconds')\n",
    "\n",
    "    return vid, videoReadTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def Video2DenseHOFVolumes(video, blockSize, numBlocks, numOr, flowMethod):\n",
    "    # Initialize lists to store HOF descriptors and their corresponding information\n",
    "    hofDesc = []\n",
    "    hofInfo = []\n",
    "\n",
    "    # Iterate over the video frames\n",
    "    for frame_idx in range(1, len(video)):\n",
    "        # Convert frames to grayscale\n",
    "        prev_gray = cv2.cvtColor(video[frame_idx - 1], cv2.COLOR_BGR2GRAY)\n",
    "        curr_gray = cv2.cvtColor(video[frame_idx], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Compute optical flow\n",
    "        flow = computeOpticalFlow(prev_gray, curr_gray, flowMethod)\n",
    "\n",
    "        # Compute HOF descriptors\n",
    "        hof = cv2.HOFDescriptor()\n",
    "        hofDesc_, hofInfo_ = hof.compute(flow, orientations=numOr, pixels_per_cell=(blockSize, blockSize), cells_per_block=(blockSize, blockSize))\n",
    "\n",
    "        # Reshape the HOF descriptors into a volume\n",
    "        hofDesc_ = hofDesc_.reshape(numBlocks, numBlocks, numOr)\n",
    "\n",
    "        # Store the HOF descriptors and their information\n",
    "        hofDesc.append(hofDesc_)\n",
    "        hofInfo.append(hofInfo_)\n",
    "\n",
    "    return hofDesc, hofInfo\n",
    "\n",
    "def computeOpticalFlow(prev_gray, curr_gray, flowMethod):\n",
    "    if flowMethod == 'dense':\n",
    "        # Compute dense optical flow using Farneback method\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, curr_gray, None, pyr_scale=0.5, levels=3, winsize=15, iterations=3, poly_n=5, poly_sigma=1.1, flags=0)\n",
    "    elif flowMethod == 'sparse':\n",
    "        # Create sparse optical flow object using Lucas-Kanade method\n",
    "        lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "        feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "        p0 = cv2.goodFeaturesToTrack(prev_gray, mask=None, **feature_params)\n",
    "\n",
    "        # Compute sparse optical flow using Lucas-Kanade method\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, p0, None, **lk_params)\n",
    "\n",
    "        # Select good points\n",
    "        good_new = p1[st == 1]\n",
    "        good_old = p0[st == 1]\n",
    "\n",
    "        # Create empty flow array\n",
    "        flow = np.zeros_like(prev_gray)\n",
    "\n",
    "        # Compute optical flow vectors\n",
    "        flow_vectors = good_new - good_old\n",
    "\n",
    "        # Assign optical flow vectors to flow array\n",
    "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            flow = cv2.line(flow, (a, b), (c, d), (0, 255, 0), 1)\n",
    "            flow = cv2.circle(flow, (a, b), 2, (0, 0, 255), -1)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid flowMethod '{flowMethod}'. Valid options are 'dense' and 'sparse'.\")\n",
    "\n",
    "    return flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(vid, videoReadTime):\n",
    "    import time\n",
    "\n",
    "    # Parameters\n",
    "    blockSize = [16, 16, 6]\n",
    "    numBlocks = [2, 2, 1]\n",
    "    numOr = 9\n",
    "    flowMethod = 'Horn-Schunck'\n",
    "\n",
    "    # For-loop over the sampling rate for HOG\n",
    "    print('\\nNow extracting HOG features. Timings below include loading the video (as in our paper):')\n",
    "    hogDesc = []\n",
    "    hogInfo = []\n",
    "    extractionTimeHOG = []\n",
    "    \n",
    "    vid = np.array(vid)\n",
    "    for frameSampleRate in [1, 2, 3, 6]:\n",
    "        start_time = time.time()\n",
    "        # Subsample framerate of video\n",
    "        sampledVid = vid[:, :, 0::frameSampleRate]\n",
    "\n",
    "        # Get correct number of frames per block\n",
    "        blockSize[2] = 6 / frameSampleRate\n",
    "\n",
    "        # Get HOG descriptors\n",
    "        hogDesc_, hogInfo_ = Video2DenseHOGVolumes(sampledVid, blockSize, numBlocks, numOr)\n",
    "        hogDesc.append(hogDesc_)\n",
    "        hogInfo.append(hogInfo_)\n",
    "\n",
    "        # Print statistics\n",
    "        extractionTimeHOG.append(time.time() - start_time)\n",
    "        totalDescriptorTime = extractionTimeHOG[-1] + videoReadTime\n",
    "        print('HOG: frames/block: {} sample rate: {} sec/vid: {:.2f} frame/sec: {:.2f}'.format(\n",
    "            blockSize[2], frameSampleRate, totalDescriptorTime, vid.shape[2] / totalDescriptorTime))\n",
    "\n",
    "    # For-loop over the sampling rate for HOF\n",
    "    print('\\nNow extracting HOF features. Timings below include loading the video (as in our paper):')\n",
    "    hofDesc = []\n",
    "    hofInfo = []\n",
    "    extractionTimeHOF = []\n",
    "    for frameSampleRate in [1, 2, 3, 6]:\n",
    "        start_time = time.time()\n",
    "        # Subsample framerate of video\n",
    "        sampledVid = vid[:, :, 0::frameSampleRate]\n",
    "\n",
    "        # Get correct number of frames per block\n",
    "        blockSize[2] = 6 / frameSampleRate\n",
    "\n",
    "        # Get HOF descriptors\n",
    "        hofDesc_, hofInfo_ = Video2DenseHOFVolumes(sampledVid, blockSize, numBlocks, numOr, flowMethod)\n",
    "        hofDesc.append(hofDesc_)\n",
    "        hofInfo.append(hofInfo_)\n",
    "\n",
    "        # Print statistics\n",
    "        extractionTimeHOF.append(time.time() - start_time)\n",
    "        totalDescriptorTime = extractionTimeHOF[-1] + videoReadTime\n",
    "        print('HOF: frames/block: {} sample rate: {} sec/vid: {:.2f} frame/sec: {:.2f}'.format(\n",
    "            blockSize[2], frameSampleRate, totalDescriptorTime, vid.shape[2] / totalDescriptorTime))\n",
    "\n",
    "    # For-loop over the sampling rate for MBH\n",
    "    print('\\nNow extracting MBH features. Timings below include loading the video (as in our paper):')\n",
    "    MBHRowDesc = []\n",
    "    MBHColDesc = []\n",
    "    mbhInfo = []\n",
    "    extractionTimeMBH = []\n",
    "    for frameSampleRate in [1, 2, 3, 6]:\n",
    "        start_time = time.time()\n",
    "        # Subsample framerate of video\n",
    "        sampledVid = vid[:, :, 0::frameSampleRate]\n",
    "\n",
    "        # Get correct number of frames per block\n",
    "        blockSize[2] = 6 / frameSampleRate\n",
    "\n",
    "        # Get MBH descriptors\n",
    "        MBHRowDesc_, MBHColDesc_, mbhInfo_ = Video2DenseMBHVolumes(sampledVid, blockSize, numBlocks, numOr, flowMethod)\n",
    "        MBHRowDesc.append(MBHRowDesc_)\n",
    "        MBHColDesc.append(MBHColDesc_)\n",
    "        mbhInfo.append(mbhInfo_)\n",
    "\n",
    "        # Print statistics\n",
    "        extractionTimeMBH.append(time.time() - start_time)\n",
    "        totalDescriptorTime = extractionTimeMBH[-1] + videoReadTime\n",
    "        print('MBH: frames/block: {} sample rate: {} sec/vid: {:.2f} frame/sec: {:.2f}'.format(\n",
    "            blockSize[2], frameSampleRate, totalDescriptorTime, vid.shape[2] / totalDescriptorTime))\n",
    "\n",
    "    # For-loop over the sampling rate for HMG\n",
    "    print('\\nNow extracting HMG features. Timings below include loading the video (as in our paper):')\n",
    "    hmgDesc = []\n",
    "    hmgInfo = []\n",
    "    extractionTimeHMG = []\n",
    "    for frameSampleRate in [1, 2, 3, 6]:\n",
    "        start_time = time.time()\n",
    "        # Subsample framerate of video\n",
    "        sampledVid = vid[:, :, 0::frameSampleRate]\n",
    "\n",
    "        # Get correct number of frames per block\n",
    "        blockSize[2] = 6 / frameSampleRate\n",
    "\n",
    "        # Get HMG descriptors\n",
    "        hmgDesc_, hmgInfo_ = Video2DenseHMGVolumes(sampledVid, blockSize, numBlocks, numOr)\n",
    "        hmgDesc.append(hmgDesc_)\n",
    "        hmgInfo.append(hmgInfo_)\n",
    "\n",
    "        # Print statistics\n",
    "        extractionTimeHMG.append(time.time() - start_time)\n",
    "        totalDescriptorTime = extractionTimeHMG[-1] + videoReadTime\n",
    "        print('HMG: frames/block: {} sample rate: {} sec/vid: {:.2f} frame/sec: {:.2f}'.format(\n",
    "            blockSize[2], frameSampleRate, totalDescriptorTime, vid.shape[2] / totalDescriptorTime))\n",
    "\n",
    "    return hogDesc, hogInfo, hofDesc, hofInfo, MBHRowDesc, MBHColDesc, mbhInfo, hmgDesc, hmgInfo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Binning & Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performBinningAndNormalization(descriptors):\n",
    "    import numpy as np\n",
    "\n",
    "    numBins = 64  # Number of bins for histogram binning\n",
    "\n",
    "    for idx in range(len(descriptors)):\n",
    "        descriptor = descriptors[idx]\n",
    "\n",
    "        # Perform binning\n",
    "        descriptor = np.histogram(descriptor.flatten(), bins=numBins, range=(0, 1))[0]\n",
    "\n",
    "        # Perform L2 normalization\n",
    "        descriptor = descriptor / np.linalg.norm(descriptor, ord=2)\n",
    "\n",
    "        # Update the descriptors\n",
    "        descriptors[idx] = descriptor\n",
    "\n",
    "    return descriptors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin & Normalize All Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinAndNormalize(hogDesc, hofDesc, MBHRowDesc, MBHColDesc, hmgDesc):\n",
    "    hogDescNorm = performBinningAndNormalization(hogDesc)\n",
    "    hofDescNorm = performBinningAndNormalization(hofDesc)\n",
    "    mbhxDescNorm = performBinningAndNormalization(MBHRowDesc)\n",
    "    mbhyDescNorm = performBinningAndNormalization(MBHColDesc)\n",
    "    hmgDescNorm = performBinningAndNormalization(hmgDesc)\n",
    "\n",
    "    return hogDescNorm, hofDescNorm, mbhxDescNorm, mbhyDescNorm, hmgDescNorm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher Vector Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def fisherVectorEncoder(vlfeatPath, hogDesc, hogInfo, hofDesc, hofInfo, MBHRowDesc, MBHColDesc, mbhInfo, hmgDesc, hmgInfo):\n",
    "    # Add VLFeat library to the MATLAB path\n",
    "    os.environ['PATH'] += os.pathsep + vlfeatPath\n",
    "    \n",
    "    # Set the desired size for the descriptors\n",
    "    desiredSize = hogDesc[0].shape\n",
    "\n",
    "    # Resize the HOG descriptors to the desired size\n",
    "    resizedHOGDesc = resizeDescriptors(hogDesc, desiredSize)\n",
    "    \n",
    "    # Resize the HOF descriptors to the desired size\n",
    "    resizedHOFDesc = resizeDescriptors(hofDesc, desiredSize)\n",
    "    \n",
    "    # Resize the MBHRow descriptors to the desired size\n",
    "    resizedMBHRowDesc = resizeDescriptors(MBHRowDesc, desiredSize)\n",
    "    \n",
    "    # Resize the MBHCol descriptors to the desired size\n",
    "    resizedMBHColDesc = resizeDescriptors(MBHColDesc, desiredSize)\n",
    "    \n",
    "    # Resize the HMG descriptors to the desired size\n",
    "    resizedHMGDesc = resizeDescriptors(hmgDesc, desiredSize)\n",
    "\n",
    "    # Load the resized descriptors from memory\n",
    "    HOG = np.concatenate(resizedHOGDesc, axis=3).astype(np.float32)\n",
    "    HOF = np.concatenate(resizedHOFDesc, axis=3).astype(np.float32)\n",
    "    MBHRow = np.concatenate(resizedMBHRowDesc, axis=3).astype(np.float32)\n",
    "    MBHCol = np.concatenate(resizedMBHColDesc, axis=3).astype(np.float32)\n",
    "    HMG = np.concatenate(resizedHMGDesc, axis=3).astype(np.float32)\n",
    "\n",
    "    # Set the number of clusters\n",
    "    K = 16\n",
    "\n",
    "    # Train the GMM for HOG\n",
    "    HOG_2D = HOG.reshape(-1, HOG.shape[3]).T\n",
    "    hogMeans, hogCovariances, hogPriors = vl_gmm(HOG_2D, K)\n",
    "\n",
    "    # Compute the Fisher vector for HOG\n",
    "    hogFisherVector = vl_fisher(HOG_2D, hogMeans, hogCovariances, hogPriors)\n",
    "\n",
    "    # Train the GMM for HOF\n",
    "    HOF_2D = HOF.reshape(-1, HOF.shape[3]).T\n",
    "    hofMeans, hofCovariances, hofPriors = vl_gmm(HOF_2D, K)\n",
    "\n",
    "    # Compute the Fisher vector for HOF\n",
    "    hofFisherVector = vl_fisher(HOF_2D, hofMeans, hofCovariances, hofPriors)\n",
    "\n",
    "    # Train the GMM for MBHRow\n",
    "    MBHRow_2D = MBHRow.reshape(-1, MBHRow.shape[3]).T\n",
    "    mbhRowMeans, mbhRowCovariances, mbhRowPriors = vl_gmm(MBHRow_2D, K)\n",
    "\n",
    "    # Compute the Fisher vector for MBHRow\n",
    "    mbhRowFisherVector = vl_fisher(MBHRow_2D, mbhRowMeans, mbhRowCovariances, mbhRowPriors)\n",
    "    \n",
    "    # Train the GMM for MBHCol\n",
    "    MBHCol_2D = MBHCol.reshape(-1, MBHCol.shape[3]).T\n",
    "    mbhColMeans, mbhColCovariances, mbhColPriors = vl_gmm(MBHCol_2D, K)\n",
    "\n",
    "    # Compute the Fisher vector for MBHCol\n",
    "    mbhColFisherVector = vl_fisher(MBHCol_2D, mbhColMeans, mbhColCovariances, mbhColPriors)\n",
    "    \n",
    "    # Train the GMM for HMG\n",
    "    HMG_2D = HMG.reshape(-1, HMG.shape[3]).T\n",
    "    hmgMeans, hmgCovariances, hmgPriors = vl_gmm(HMG_2D, K)\n",
    "\n",
    "    # Compute the Fisher vector for HMG\n",
    "    hmgFisherVector = vl_fisher(HMG_2D, hmgMeans, hmgCovariances, hmgPriors)\n",
    "\n",
    "    # Save the GMM parameters to disk\n",
    "    with open('gmm_hog.pkl', 'wb') as f:\n",
    "        pickle.dump((hogMeans, hogCovariances, hogPriors), f)\n",
    "    with open('gmm_hof.pkl', 'wb') as f:\n",
    "        pickle.dump((hofMeans, hofCovariances, hofPriors), f)\n",
    "    with open('gmm_mbh.pkl', 'wb') as f:\n",
    "        pickle.dump((mbhRowMeans, mbhRowCovariances, mbhRowPriors, mbhColMeans, mbhColCovariances, mbhColPriors), f)\n",
    "    with open('gmm_hmg.pkl', 'wb') as f:\n",
    "        pickle.dump((hmgMeans, hmgCovariances, hmgPriors), f)\n",
    "\n",
    "    # Save the encoded features to a file\n",
    "    np.save('hog_fisher_vector.npy', hogFisherVector)\n",
    "    np.save('hof_fisher_vector.npy', hofFisherVector)\n",
    "    np.save('mbh_row_fisher_vector.npy', mbhRowFisherVector)\n",
    "    np.save('mbh_col_fisher_vector.npy', mbhColFisherVector)\n",
    "    np.save('hmg_fisher_vector.npy', hmgFisherVector)\n",
    "\n",
    "    # Print the dimensions of each Fisher vector\n",
    "    print('HOG Fisher vector dimensions:', hogFisherVector.shape)\n",
    "    print('HOF Fisher vector dimensions:', hofFisherVector.shape)\n",
    "    print('MBH Row Fisher vector dimensions:', mbhRowFisherVector.shape)\n",
    "    print('MBH Col Fisher vector dimensions:', mbhColFisherVector.shape)\n",
    "    print('HMG Fisher vector dimensions:', hmgFisherVector.shape)\n",
    "\n",
    "    print('Fisher vector encoding done!')\n",
    "\n",
    "def resizeDescriptors(desc, desiredSize):\n",
    "    resizedDesc = []\n",
    "    for d in desc:\n",
    "        resizedDesc.append(cv2.resize(d, desiredSize))\n",
    "    return resizedDesc\n",
    "\n",
    "def vl_gmm(X, K):\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    gmm = GaussianMixture(n_components=K, covariance_type='diag')\n",
    "    gmm.fit(X)\n",
    "    means = gmm.means_.T\n",
    "    covariances = gmm.covariances_.T\n",
    "    priors = gmm.weights_\n",
    "    return means, covariances, priors\n",
    "\n",
    "def vl_fisher(X, means, covariances, priors):\n",
    "    from fisher_vectors import FisherVectors\n",
    "    fv = FisherVectors(means, covariances, priors)\n",
    "    fisher_vector = fv.transform(X)\n",
    "    return fisher_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performLabelEncoding(subjectNames):\n",
    "    # Unique subject names\n",
    "    unique_names = list(set(subjectNames))\n",
    "\n",
    "    # Create a mapping between subject names and integer labels\n",
    "    label_map = {name: label for label, name in enumerate(unique_names, start=1)}\n",
    "\n",
    "    # Perform label encoding\n",
    "    encoded_labels = [label_map[name] for name in subjectNames]\n",
    "\n",
    "    print('\\nEncoded Labels:')\n",
    "    print(encoded_labels)\n",
    "\n",
    "    return encoded_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenateFisherVectors(hogFisherVector, hofFisherVector, mbhRowFisherVector, mbhColFisherVector, hmgFisherVector):\n",
    "    # Concatenate the Fisher vectors\n",
    "    concatenated_vectors = np.concatenate((hogFisherVector, hofFisherVector, mbhRowFisherVector, mbhColFisherVector, hmgFisherVector), axis=1)\n",
    "\n",
    "    # Save the concatenated vectors\n",
    "    np.save('concatenated_vectors.npy', concatenated_vectors)\n",
    "\n",
    "    # Display the concatenated vectors\n",
    "    print('\\nConcatenated Fisher Vectors:')\n",
    "    print(concatenated_vectors)\n",
    "\n",
    "    return concatenated_vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Concatenated Vectors With Encoded Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveConcatWithLabels(matrix, value, seq):\n",
    "    filename = 'concat_with_labels.npy'\n",
    "\n",
    "    concatenated_values = np.concatenate((matrix, np.full((matrix.shape[0], 1), value), np.full((matrix.shape[0], 1), seq)), axis=1)\n",
    "\n",
    "    try:\n",
    "        existing_matrix = np.load(filename)\n",
    "        result = np.concatenate((existing_matrix, concatenated_values), axis=0)\n",
    "    except FileNotFoundError:\n",
    "        result = concatenated_values\n",
    "\n",
    "    np.save(filename, result)\n",
    "\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allVidsPCA():\n",
    "\n",
    "    # Load the data from the numpy file\n",
    "    data = np.load('concat_with_labels.npy')\n",
    "\n",
    "    # Extract the necessary columns for PCA\n",
    "    pcaData = data[:, :-2]\n",
    "\n",
    "    # Perform PCA\n",
    "    desiredVariance = 0.96\n",
    "    pca = PCA(n_components=desiredVariance)\n",
    "    pcaScores = pca.fit_transform(pcaData)\n",
    "\n",
    "    # Append the last two columns to the PCA scores\n",
    "    pcaScores = np.concatenate((pcaScores, data[:, -2:]), axis=1)\n",
    "\n",
    "    # Save the PCA scores to a file\n",
    "    np.save('allvids_pca_scores.npy', pcaScores)\n",
    "\n",
    "    print(pcaScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def run_disp_SVM():\n",
    "    # Load the PCA scores and labels from the numpy file\n",
    "    data = np.load('allvids_pca_scores.npy')\n",
    "    pcaScores = data\n",
    "\n",
    "    # Separate the last column (testing/training indicator) and second last column (labels)\n",
    "    testingIndicator = pcaScores[:, -1]\n",
    "    labels = pcaScores[:, -2]\n",
    "\n",
    "    # Find the indices for testing and training data\n",
    "    testingIndices = (testingIndicator == 4)\n",
    "\n",
    "    # Separate training and testing data\n",
    "    trainingData = pcaScores[~testingIndices, :-2]\n",
    "    trainingLabels = labels[~testingIndices]\n",
    "    testingData = pcaScores[testingIndices, :-2]\n",
    "    testingLabels = labels[testingIndices]\n",
    "\n",
    "    # Train the SVM classifier\n",
    "    model = SVC()\n",
    "    model.fit(trainingData, trainingLabels)\n",
    "\n",
    "    # Predict labels for testing data\n",
    "    predictedLabels = model.predict(testingData)\n",
    "\n",
    "    # Calculate the accuracy of the SVM classifier\n",
    "    accuracy = accuracy_score(testingLabels, predictedLabels) * 100\n",
    "\n",
    "    # Display the accuracy of the SVM classifier\n",
    "    print('SVM Accuracy:')\n",
    "    print(accuracy)\n",
    "\n",
    "    # Print the results for all subjects\n",
    "    print('Subject Results:')\n",
    "    subjects = np.unique(testingLabels)\n",
    "    for subject in subjects:\n",
    "        subjectIndices = (testingLabels == subject)\n",
    "        subjectPredictions = predictedLabels[subjectIndices]\n",
    "        subjectAccuracy = accuracy_score(np.full_like(subjectPredictions, subject), subjectPredictions) * 100\n",
    "        print('Subject', subject, ':')\n",
    "        print('Accuracy:', subjectAccuracy)\n",
    "        print('Predictions:', subjectPredictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runFisherConcatPCA(videoPath, subjectName, sequenceName):\n",
    "    # Load the video and get the read time\n",
    "    vid, videoReadTime = loadVideo(videoPath)\n",
    "\n",
    "    # Extract features\n",
    "    hogDesc, hogInfo, hofDesc, hofInfo, MBHRowDesc, MBHColDesc, mbhInfo, hmgDesc, hmgInfo = extractFeatures(vid, videoReadTime)\n",
    "\n",
    "    # Performing binning & normalization\n",
    "    hogDescNorm, hofDescNorm, mbhxDescNorm, mbhyDescNorm, hmgDescNorm = BinAndNormalize(hogDesc, hofDesc, MBHRowDesc, MBHColDesc, hmgDesc)\n",
    "    \n",
    "    # Set vlfeat path\n",
    "    vlfeatPath = 'E:\\bsef19m501\\vlfeat-0.9.21-bin'\n",
    "\n",
    "    subjectNames = ['fyc', 'hy', 'ljg', 'lqf', 'lsl', 'ml', 'nhz', 'rj', 'syj', 'wl', 'wq', 'wyc', 'xch', 'xxj', 'yjf', 'zc', 'zdx', 'zjg', 'zl', 'zyf']\n",
    "\n",
    "    # Perform label encoding\n",
    "    encoded_labels = performLabelEncoding(subjectNames)\n",
    "\n",
    "    # Find the encoded label for the given subject name\n",
    "    encodedLabel = encoded_labels[subjectNames.index(subjectName)]\n",
    "\n",
    "    print('\\nEncoded Label for Current Subject:')\n",
    "    print(encodedLabel)\n",
    "\n",
    "    # Perform Fisher Vector Encoding\n",
    "    hogFisherVector, hofFisherVector, mbhRowFisherVector, mbhColFisherVector, hmgFisherVector = fisherVectorEncoder(vlfeatPath, hogDescNorm, hogInfo, hofDescNorm, hofInfo, mbhxDescNorm, mbhyDescNorm, mbhInfo, hmgDescNorm, hmgInfo)\n",
    "\n",
    "    # Concatenate after Fisher Vector Encoding\n",
    "    concatenated_vectors = concatenateFisherVectors(hogFisherVector, hofFisherVector, mbhRowFisherVector, mbhColFisherVector, hmgFisherVector)\n",
    "\n",
    "    saveConcatWithLabels(concatenated_vectors, encodedLabel, sequenceName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caller Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subject Folder: fyc\n",
      "\n",
      "Sequence Folder: fyc/00_1\n",
      "\n",
      "Video Path: fyc00_1.avi\n",
      "\n",
      "Videos\\fyc\\00_1\\fyc00_1.avi\n",
      "Video Path: C:\\Users\\LENOVO\\Desktop\\AIM\\Videos\\fyc\\00_1\\fyc00_1.avi\n",
      "\n",
      "Using VideoReader from Matlab to load video.\n",
      "Warning: We found that loading videos using native Matlab code took more time than the HOG features sampled at every frame. Instead, using the external library mmread to load a video is faster. See comments in your code for more information.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'VideoReadNative' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c80f6bdb37b2>\u001b[0m in \u001b[0;36mloadVideo\u001b[1;34m(videoPath)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# Using mmread to load video\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[0mmmread\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVideoRead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mmread'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c9f2931b2f57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# runFisherConcatPCA(videoPath, subjectName, sequenceName)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mrunCode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-c9f2931b2f57>\u001b[0m in \u001b[0;36mrunCode\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;31m# runCompleteCode(videoPath)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mrunFisherConcatPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideoPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubjectName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequenceName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;31m# runNewCode(videoPath, subjectName, sequenceName)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-a051c739f425>\u001b[0m in \u001b[0;36mrunFisherConcatPCA\u001b[1;34m(videoPath, subjectName, sequenceName)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrunFisherConcatPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideoPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubjectName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequenceName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Load the video and get the read time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mvid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvideoReadTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadVideo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideoPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Extract features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-c80f6bdb37b2>\u001b[0m in \u001b[0;36mloadVideo\u001b[1;34m(videoPath)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# Call your own implementation of VideoReadNative()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mvid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoReadNative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideoPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mvideoReadTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Loaded video in {videoReadTime:.2f} seconds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VideoReadNative' is not defined"
     ]
    }
   ],
   "source": [
    "def runCode():\n",
    "    # Iterate over the subject folders\n",
    "    subjectNames = ['fyc', 'hy', 'ljg', 'lqf', 'lsl', 'ml', 'nhz', 'rj', 'syj', 'wl', 'wq', 'wyc', 'xch', 'xxj', 'yjf', 'zc', 'zdx', 'zjg', 'zl', 'zyf']\n",
    "    \n",
    "    for subjectName in subjectNames:\n",
    "        subjectFolder = subjectName\n",
    "        print(f'\\nSubject Folder: {subjectFolder}\\n')\n",
    "        \n",
    "        # Iterate over the sequence folders for each subject\n",
    "        sequenceNames = ['00_1', '00_2', '00_3', '00_4']\n",
    "        \n",
    "        for sequenceName in sequenceNames:\n",
    "            sequenceFolder = f'{subjectFolder}/{sequenceName}'\n",
    "            print(f'Sequence Folder: {sequenceFolder}\\n')\n",
    "            \n",
    "            # Construct the video filename\n",
    "            videoFilename = subjectName + sequenceName\n",
    "            videoPath = f'{videoFilename}.avi'\n",
    "            print(f'Video Path: {videoPath}\\n')\n",
    "            completePath = 'Videos\\\\'+ subjectName + '\\\\' + sequenceName + '\\\\' + videoPath\n",
    "            print(completePath)\n",
    "            \n",
    "            # Process the video file as needed\n",
    "            # print(videoPath)\n",
    "\n",
    "            # Run complete code\n",
    "            videoPath = os.path.join(os.getcwd(), completePath )\n",
    "            print(f'Video Path: {videoPath}\\n')\n",
    "            \n",
    "            # runCompleteCode(videoPath)\n",
    "\n",
    "            runFisherConcatPCA(videoPath, subjectName, sequenceName)\n",
    "\n",
    "            # runNewCode(videoPath, subjectName, sequenceName)\n",
    "\n",
    "\n",
    "# videoPath = os.path.join(os.getcwd(), 'v_HulaHoop_g11_c04.avi')\n",
    "# runFisherConcatPCA(videoPath, subjectName, sequenceName)\n",
    "\n",
    "runCode()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
